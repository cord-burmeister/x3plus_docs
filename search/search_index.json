{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"X3Plus robot project description","text":"<p>ROS 2 description of X3 Plus robot</p> <p>Note: This repository is still under construction</p> <p></p>"},{"location":"00-General/000-Introduction/","title":"Introduction","text":"<p>The path wasn\u2019t easy. </p> <p>Robots have a great fascination, but turning that fascination into a reality was a journey filled with challenges, learning curves, and moments of triumph. This book is a chronicle of that journey\u2014a guide through the world of robotics, from the first spark of an idea to the intricate dance of hardware and software.</p>"},{"location":"00-General/000-Introduction/#the-collective-spark-from-ros-community-to-living-hardware","title":"The Collective Spark \u2013 From ROS Community to Living Hardware","text":"<p>Innovation wasn\u2019t born in isolation. It thrived in community. And in the world of robotics, no community was more vibrant, diverse, and open than the ROS ecosystem.</p>"},{"location":"00-General/000-Introduction/#the-ros-community-a-global-brain","title":"The ROS Community: A Global Brain","text":"<p>The Robot Operating System (ROS) isn\u2019t just software\u2014it\u2019s a movement. Thousands of developers, researchers, and hobbyists contribute to its libraries, tools, and packages. From Stanford labs to garage workshops in Bavaria, ROS is the common language of roboticists.</p> <ul> <li>Federated Collaboration: Sub-communities form around shared goals\u2014navigation, manipulation, drones, humanoids. Each group contributes code, documentation, and support.</li> <li>Events &amp; Meetups: Annual conferences like ROSCon and local ROSCon events showcase breakthroughs and foster collaboration.</li> <li>Online Hubs: Platforms like ROS Discourse and GitHub host discussions, tutorials, and open-source packages. Cord often found answers to obscure bugs in threads from halfway across the world.</li> </ul>"},{"location":"00-General/000-Introduction/#software-meets-hardware","title":"Software Meets Hardware","text":"<p>Robots aren\u2019t just a software marvel\u2014they have bones and muscles. Integrating ROS with hardware was the next leap.</p> <ul> <li>Hardware Abstraction Layer (HAL): ROS standardized how software talks to sensors, motors, and actuators. Developers could swap out a LiDAR or motor driver without rewriting the entire codebase.</li> <li>Sensor Integration: Using ROS drivers, they connected a depth camera, IMU, and ultrasonic sensors. Each streamed data into ROS topics, ready for processing.</li> <li>Motion Planning: With packages like MoveIt and Nav2, the robot could navigate rooms, avoid obstacles, and even gesture with its arm.</li> </ul>"},{"location":"00-General/000-Introduction/#the-first-real-test","title":"The First Real Test","text":"<p>The robot was wheeled into the hallway. It scanned the environment, built a map, and plotted a path to the kitchen. The motors hummed, sensors blinked, and the robot moved\u2014smoothly, purposefully.</p> <p>It wasn\u2019t just executing commands. It was responding, adapting, learning. And behind every line of code was a community that had helped make it possible.</p>"},{"location":"00-General/010-Motivation/","title":"Motivation","text":"<p>In recent years, the field of robotics has seen unprecedented growth, driven by advancements in hardware, artificial intelligence, and automation. Robots are no longer confined to industrial settings; they are becoming integral to healthcare, agriculture, logistics, and even our homes. However, building a functional and efficient robot remains a complex challenge, requiring a seamless integration of mechanical design, electronics, and software.</p> <p>This project aims to have a environment to explore and learn in the world of robotics.</p> <p>The motivation behind this project is the following:</p> <ul> <li> <p>Education and Learning: Robotics is an interdisciplinary field that combines engineering, computer science, and mathematics. This project provides an opportunity to explore these domains in a hands-on manner.</p> </li> <li> <p>New Technology: By leveraging hardware components and open-source software, this project seeks to explore which capabilities are required to address certain use cases.</p> </li> </ul> <p>Ultimately, this project is driven by a vision to learn and explore robotics.</p>"},{"location":"00-General/020-Levels-of-Autonomy-for-Robots/","title":"Levels of Autonomy for Robots","text":""},{"location":"00-General/020-Levels-of-Autonomy-for-Robots/#introduction","title":"Introduction","text":"<p>Stakeholders in a large variety of industries are considering autonomous robots. However, we are still some time away from achieving reliable and robust long-term autonomy in the real world. Fortunately, even at the current levels of autonomy, robots can be deployed to help with a variety of tasks and deliver significant benefit to end-users across industries.</p>"},{"location":"00-General/020-Levels-of-Autonomy-for-Robots/#levels-of-autonomy","title":"Levels of Autonomy","text":"<p>Thinking of autonomy as a long-term objective with a levels-based framework will help achieve realistic real-world deployments. Increasing levels of autonomy should be designed to increasingly simplify human user experience. Starting from the human having to control almost all aspects of the robotic system (Level 0), all the way to the team of robots carrying out specific tasks in dynamic and unstructured environments adapting and learning beyond what the designer or the user programmed (Level 5).</p> Level Description Time between Interventions 0 Full manual teleoperation n/a 1 Robot within line of sight (hands off) 5 minutes 2 Operator on site or nearby (eyes off) 1 hour 3 One operator oversees many robots (mind off) 8 hours 4 Supervisor not on site (monitoring off) 3 days 5 Robots adapt and improve execution (development off) extended operation <p>The levels of autonomy are designed to describe how autonomous a robot is in executing a task. They tie back to the attention a human supervisor has to provide the robot or a team of robots while they are executing the task.</p>"},{"location":"00-General/020-Levels-of-Autonomy-for-Robots/#level-1-autonomy-hands-off","title":"Level 1 Autonomy (hands off)","text":"<p>A human needs to be always within line of sight of the robot. For example, in the agricultural automation system shown in the picture below, a human must always follow a robot as it goes through the field. Simple reactive tasks such as keeping the robot in the center of the row or spraying when a weed is detected are automated. A widely deployed example of autonomous systems at this level of autonomy are GPS guided tractors. Here, the human is required to be in the cab to take care of unforeseen events, but the tractor drives itself on pre-programmed paths.</p>"},{"location":"00-General/020-Levels-of-Autonomy-for-Robots/#level-2-autonomy-eyes-off","title":"Level 2 Autonomy (eyes off)","text":"<p>Now, the human operators switch to being (remote) supervisors: They don\u2019t have to follow the robot, the robot may be out of line of sight, but the human still must remain on the field and keep monitoring the robot in case it needs rescuing. This capability is an enabling-point for high-value applications in many industries. For example at Level 2, an agricultural robot might be able to navigate a way-point prescribed path avoiding most obstacles, and only get stumped once in a while. The target time between interventions increases to about an hour. At this level of autonomy, the human may be able to do other tasks on the field, but likely only have one or two robots running autonomously under their supervision.</p>"},{"location":"00-General/020-Levels-of-Autonomy-for-Robots/#level-3-autonomy-mind-off","title":"Level 3 Autonomy (mind off)","text":"<p>In many industries, Level 3 autonomy represents an inflection point where large-scale deployments become quite attractive. A Level 3 robotic team is sufficiently capable of dealing with edge cases for several days so that a single human can monitor a number of robots. This is where most multi-robot based farming systems begin to scale up. The human still might need to be on the field though to swap batteries, perform repairs, or rescue a stranded robot every so often.</p>"},{"location":"00-General/020-Levels-of-Autonomy-for-Robots/#level-4-autonomy-monitoring-off","title":"Level 4 Autonomy (monitoring off)","text":"<p>At level 4, autonomous robots can really be deployed at large scale, without being constrained by labor costs. Level 4 autonomous robot teams are capable of dealing with many of the edge cases themselves, becoming sufficiently autonomous so that the human doesn\u2019t feel the need to be on the field. They also have sufficient automated support infrastructure on-site. The robots are capable of finding their base stations, get a new battery, perform minor repairs, and get out of difficult cases (perhaps with help from a remote human). This level of autonomy needs not only the on robot software to mature, but the on-field infrastructure to automate and typically a reliable connection with remote users.</p>"},{"location":"00-General/020-Levels-of-Autonomy-for-Robots/#level-5-autonomy-development-off","title":"Level 5 Autonomy (development off)","text":"<p>At level 5, the robots begin to learn from  their experience to improve operation beyond what the human designer has programmed in. They learn from each other, on site and from robot teams from other sites. They learn to predict how events affect their capabilities and plan proactively.</p> <p>As an example of how human interaction with the system changes with increasing levels of autonomy, consider the following with the multi-robot agricultural autonomy example: At Level 3, the human on the field is responsible for organizing field activity if it is going to rain. At Level 4, the robot team uses data from the internet to determine when to go out based on the weather. At level 5, the robot team, anticipating its going to rain tomorrow, learns to take care of tasks on the day before!</p>"},{"location":"00-General/020-Levels-of-Autonomy-for-Robots/#references","title":"References","text":"<p>Levels of Autonomy for Field Robots</p> <p>SAE Levels of Driving Automation\u2122 Refined for Clarity and International Audience</p> <p>The 6 Levels of Vehicle Autonomy Explained</p>"},{"location":"00-General/030-Topic-Areas/","title":"Topics","text":"<p>This chapter contains a list of topics that are relevant to the project. The topics are organized into autonomy categories, and each category contains a list of subtopics. The topics are not exhaustive, but they provide a good starting point for further exploration.</p>"},{"location":"00-General/030-Topic-Areas/#topics-overview","title":"Topics overview","text":""},{"location":"00-General/030-Topic-Areas/#general-topics","title":"General Topics","text":"<p>This section provides an overview of the general topics that are relevant to the project. These topics are not specific to any level of autonomy, but they provide a foundation for understanding the project.</p> <p></p>"},{"location":"00-General/030-Topic-Areas/#level-0-topics","title":"Level 0 Topics","text":"<p>This section provides an overview of the topics that are relevant to the Level 0 autonomy category. These topics are focused on manual control and basic robot operation.</p> <p></p>"},{"location":"00-General/030-Topic-Areas/#level-1-topics","title":"Level 1 Topics","text":"<p>This section provides an overview of the topics that are relevant to the Level 1 autonomy category. These topics are focused on hands-off robot operation and autonomy.</p> <p></p>"},{"location":"00-General/030-Topic-Areas/#level-2-topics","title":"Level 2 Topics","text":"<p>This section provides an overview of the topics that are relevant to the Level 2 autonomy category. These topics are focused on more advanced robot operation and autonomy.</p> <p></p>"},{"location":"00-General/100-Repository-Structure/","title":"Repository structure","text":"<p>Boot strap scripts of the robot project.</p>"},{"location":"00-General/100-Repository-Structure/#project-description","title":"Project Description","text":"<p>The <code>x3plus_setup</code> project is designed to provide a set of bootstrap scripts for setting up the development environment and workspace for the X3Plus robot project. The goal of this project is to simplify the process of getting started with the X3Plus robot by automating the installation of necessary dependencies and configuration of the development environment.</p>"},{"location":"00-General/100-Repository-Structure/#project-structure","title":"Project structure","text":""},{"location":"00-General/100-Repository-Structure/#development-environment-setup","title":"Development Environment Setup","text":""},{"location":"00-General/100-Repository-Structure/#prerequisites","title":"Prerequisites","text":"<p>Before running the setup scripts, ensure that you have the following dependencies installed:</p> <ul> <li>Ubuntu 22.04 or later</li> <li>ROS 2 Humble Hawksbill</li> </ul>"},{"location":"00-General/100-Repository-Structure/#instructions","title":"Instructions","text":"<ol> <li>Clone the repository:</li> </ol> <pre><code>git clone https://github.com/cord-burmeister/x3plus_setup.git\ncd x3plus_setup\n</code></pre> <ol> <li>Run the setup script for ROS 2 Humble:</li> </ol> <pre><code>bash bash/setup-humble.sh\n</code></pre>"},{"location":"00-General/100-Repository-Structure/#running-the-setup-scripts","title":"Running the Setup Scripts","text":"<p>The <code>x3plus_setup</code> project provides several setup scripts to configure different workspaces for the X3Plus robot. Below are the instructions for running each setup script:</p>"},{"location":"00-General/100-Repository-Structure/#bashsetup-humblesh","title":"<code>bash/setup-humble.sh</code>","text":"<p>This script sets up the ROS 2 Humble environment and installs the necessary dependencies.</p>"},{"location":"00-General/100-Repository-Structure/#bashsetup-ws-botsh","title":"<code>bash/setup-ws-bot.sh</code>","text":"<p>This script sets up the workspace for the X3Plus robot controller.</p>"},{"location":"00-General/100-Repository-Structure/#bashsetup-ws-gzsh","title":"<code>bash/setup-ws-gz.sh</code>","text":"<p>This script sets up the workspace for the X3Plus Gazebo simulation.</p>"},{"location":"00-General/100-Repository-Structure/#bashsetup-ws-pitsh","title":"<code>bash/setup-ws-pit.sh</code>","text":"<p>This script sets up the workspace for the X3Plus development and cockpit environment.</p> <p>To run any of these scripts, use the following command:</p> <pre><code>bash &lt;script-name&gt;.sh\n</code></pre> <p>Replace <code>&lt;script-name&gt;</code> with the name of the script you want to run.</p>"},{"location":"00-General/100-Repository-Structure/#project-structure-and-components","title":"Project Structure and Components","text":"<p>The <code>x3plus_setup</code> project consists of the following components:</p> <ul> <li><code>bash/</code>: Directory containing the setup scripts.</li> <li><code>docu/</code>: Directory containing documentation files.</li> <li><code>LICENSE</code>: License file for the project.</li> <li><code>README.md</code>: This file, containing the project documentation.</li> </ul>"},{"location":"00-General/100-Repository-Structure/#known-issues-and-limitations","title":"Known Issues and Limitations","text":"<ul> <li>The setup scripts are designed to work on Ubuntu 2s.04 or later. Compatibility with other operating systems is not guaranteed.</li> <li>Some dependencies may require manual installation if they are not available through the package manager.</li> </ul>"},{"location":"00-General/200-Deployment-Models/","title":"Deployment Models","text":"<p>Deployment models refer to the various ways in which software applications can be deployed and made available to users. The choice of deployment model can significantly affect the performance, scalability, and cost of an application. Here are some common deployment models:</p>"},{"location":"00-General/200-Deployment-Models/#ros-deployment-models","title":"ROS Deployment Models","text":""},{"location":"00-General/200-Deployment-Models/#1-totally-autonomous","title":"1. Totally Autonomous","text":"<p>In this model, all ROS nodes and computation run directly on the robot\u2019s onboard computer(s). The robot operates independently, without relying on external servers or networks. This is ideal for scenarios where connectivity is unreliable or unavailable, and low-latency, real-time processing is required.</p> <p>Pros:</p> <ul> <li>No dependency on external infrastructure  </li> <li>Low latency  </li> <li>High reliability in disconnected environments</li> </ul> <p>Cons: </p> <ul> <li>Limited by onboard hardware resources  </li> <li>Harder to update or monitor remotely</li> </ul>"},{"location":"00-General/200-Deployment-Models/#2-distributed-with-calculation-backend","title":"2. Distributed with Calculation Backend","text":"<p>Here, the robot runs a subset of ROS nodes locally (e.g., for sensor data acquisition and basic control), while offloading heavy computation (such as SLAM, object recognition, or planning) to a remote backend server, often over a network. This allows for more complex processing than the robot could handle alone.</p> <p>Pros:</p> <ul> <li>Access to greater computational resources  </li> <li>Easier to update and monitor backend algorithms</li> </ul> <p>Cons:</p> <ul> <li>Dependent on network connectivity and bandwidth  </li> <li>Potential for increased latency</li> </ul>"},{"location":"00-General/200-Deployment-Models/#3-autonomous-with-teleoperation","title":"3. Autonomous with Teleoperation","text":"<p>In this model, the robot operates autonomously for most tasks but allows a human operator to intervene or take control remotely when needed. Teleoperation can be used for supervision, troubleshooting, or handling complex situations that the robot cannot resolve on its own. Communication is typically established over a network, enabling real-time or near-real-time control and feedback.</p> <p>Pros:</p> <ul> <li>Combines autonomy with human oversight  </li> <li>Increases safety and flexibility  </li> <li>Enables remote troubleshooting and support</li> </ul> <p>Cons:</p> <ul> <li>Requires reliable network connectivity for teleoperation  </li> <li>May introduce latency during manual control  </li> <li>Human intervention may be needed in unexpected scenarios</li> </ul>"},{"location":"00-General/200-Deployment-Models/#4-simulation","title":"4. Simulation","text":"<p>In simulation deployment, all ROS nodes run on a desktop or server, often using tools like Gazebo or RViz to simulate the robot and its environment. This is used for development, testing, and validation before deploying to real hardware.</p> <p>Pros: </p> <ul> <li>Safe and cost-effective for testing  </li> <li>Easy to iterate and debug</li> </ul> <p>Cons: </p> <ul> <li>May not capture all real-world complexities  </li> <li>Performance may differ from real hardware</li> </ul> <p>These models can be combined or adapted depending on the application requirements and available resources.</p>"}]}